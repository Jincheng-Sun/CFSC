{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models, Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dropout, GlobalAveragePooling2D, add, Input, Dense,MaxPool2D\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import sys\n",
    "sys.path.append('/root/oneclick/CFSC/CFSC/')\n",
    "from Training.Networks import Res50\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_relu(layer, dropout=0, **params):\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation(params['conv_activation'])(layer)\n",
    "\n",
    "    if dropout > 0:\n",
    "        layer = Dropout(dropout)(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def global_average_pooling(layer, cls):\n",
    "    layer = Conv2D(cls, [1, 1])(layer)\n",
    "    layer = GlobalAveragePooling2D()(layer)\n",
    "    layer = Activation(activation='softmax')(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block_A(layer, filters, kernels, dropout, activation, cross_block=False,shrink = False):\n",
    "    # -Conv-BN-Act-Conv-BN-Act-\n",
    "    # ↳-----Conv-BN-Act-------↑\n",
    "\n",
    "    shape = [1, 1]\n",
    "    if shrink:\n",
    "        shape = [2, 2]\n",
    "\n",
    "    if cross_block:\n",
    "        shortcut = Conv2D(filters=filters,\n",
    "                          kernel_size=shape,\n",
    "                          kernel_initializer='random_uniform',\n",
    "                          # kernel_regularizer=regularizers.l2(0.01),\n",
    "                          strides=shape,\n",
    "                          padding='same')(layer)\n",
    "        shortcut = bn_relu(shortcut,conv_activation='relu')\n",
    "    else:\n",
    "        shortcut = layer\n",
    "\n",
    "    layer = Conv2D(filters=filters,\n",
    "                   kernel_size=kernels,\n",
    "                   kernel_initializer='random_uniform',\n",
    "                   # kernel_regularizer=regularizers.l2(0.01),\n",
    "                   strides=shape,\n",
    "                   padding='same')(layer)\n",
    "    layer = bn_relu(layer, dropout=dropout, conv_activation=activation)\n",
    "\n",
    "    layer = Conv2D(filters=filters,\n",
    "                   kernel_size=kernels,\n",
    "                   kernel_initializer='random_uniform',\n",
    "                   # kernel_regularizer=regularizers.l2(0.01),\n",
    "                   strides=[1, 1],\n",
    "                   padding='same')(layer)\n",
    "\n",
    "\n",
    "    layer = bn_relu(layer, dropout=dropout, conv_activation=activation)\n",
    "\n",
    "    layer = add([shortcut, layer])\n",
    "\n",
    "    # if shrink:\n",
    "    #     layer = MaxPool2D()(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet_A(num):\n",
    "    input = Input(shape=[100, 100, 1])\n",
    "    #100*100\n",
    "    layer1 = resnet_block_A(layer = input, filters= 32, kernels=[3,3],\n",
    "                           dropout= 0,activation = 'relu',cross_block= True)\n",
    "    layer2 = resnet_block_A(layer = layer1, filters= 32, kernels=[3,3],\n",
    "                           dropout= 0,activation = 'relu')\n",
    "    #50*50\n",
    "    layer3 = resnet_block_A(layer=layer2, filters=64, kernels=[3, 3],\n",
    "                           dropout=0, activation='relu',cross_block= True,shrink=True)\n",
    "    layer4 = resnet_block_A(layer = layer3, filters= 64, kernels=[3,3],\n",
    "                           dropout= 0,activation = 'relu')\n",
    "    #25*25\n",
    "    layer5 = resnet_block_A(layer=layer4, filters=128, kernels=[3, 3],\n",
    "                           dropout=0, activation='relu', cross_block=True, shrink=True)\n",
    "    layer6 = resnet_block_A(layer=layer5, filters=128, kernels=[3, 3],\n",
    "                                   dropout=0, activation='relu')\n",
    "    #13*13\n",
    "    layer7 = resnet_block_A(layer=layer6, filters=256, kernels=[3, 3],\n",
    "                           dropout=0, activation='relu', cross_block=True, shrink=True)\n",
    "    layer8 = resnet_block_A(layer=layer7, filters=256, kernels=[3, 3],\n",
    "                                   dropout=0, activation='relu')\n",
    "    #7*7\n",
    "    layer9 = resnet_block_A(layer=layer8, filters=512, kernels=[3, 3],\n",
    "                           dropout=0, activation='relu', cross_block=True, shrink=True)\n",
    "    layer10 = resnet_block_A(layer=layer9, filters=512, kernels=[3, 3],\n",
    "                                   dropout=0, activation='relu')\n",
    "\n",
    "\n",
    "    output = global_average_pooling(layer10, num)\n",
    "    model = Model(inputs = [input], outputs = [output])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    num = 40000\n",
    "    X_train = np.load('../data/train_x.npy')[0:num]\n",
    "    Y_train = np.load('../data/train_y.npy')[0:num]\n",
    "    #Y_train = Y_train[:]\n",
    "    X_train = np.reshape(X_train, [num, 100, 100, 1])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "    y_train = pd.DataFrame(y_train)[0]\n",
    "    y_val = pd.DataFrame(y_val)[0]\n",
    "    # one-hot，5 category\n",
    "    y_labels = list(y_train.value_counts().index)\n",
    "    y_labels = list(range(157))\n",
    "    # y_labels = np.unique(y_train)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_labels)\n",
    "    num_labels = len(y_labels)\n",
    "    y_train = to_categorical(y_train.map(lambda x: le.transform([x])[0]), num_labels)\n",
    "    y_val = to_categorical(y_val.map(lambda x: le.transform([x])[0]), num_labels)\n",
    "\n",
    "    adam = optimizers.adam(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=50,\n",
    "              epochs=20,\n",
    "              validation_data=(x_val, y_val),\n",
    "              callbacks=[monitor])\n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    val_loss = score[0]\n",
    "    acc = score[1]\n",
    "    model.save('../models/RCNN')\n",
    "    X_test = np.load('../data/test_x.npy')\n",
    "    Y_test = np.load('../data/test_y.npy')\n",
    "    # X_train reshape to [40000,100,100]\n",
    "    X_test = np.reshape(X_test, [4000, 100, 100, 1])\n",
    "    Y_test = Y_test[:,0]\n",
    "    score = model.predict(X_test)\n",
    "    score = np.argmax(score, axis=1)\n",
    "    score = accuracy_score(score, Y_test)\n",
    "\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 100, 100, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 100, 100, 32) 320         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 100, 100, 32) 128         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 100, 100, 32) 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 100, 100, 32) 64          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 100, 100, 32) 9248        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 100, 100, 32) 128         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 100, 100, 32) 128         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 100, 100, 32) 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 100, 100, 32) 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 100, 100, 32) 0           activation_144[0][0]             \n",
      "                                                                 activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 100, 100, 32) 9248        add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 100, 100, 32) 128         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 100, 100, 32) 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 100, 100, 32) 9248        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 100, 100, 32) 128         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 100, 100, 32) 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 100, 100, 32) 0           add_50[0][0]                     \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 50, 50, 64)   18496       add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 50, 50, 64)   256         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 50, 50, 64)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 50, 50, 64)   8256        add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 50, 50, 64)   36928       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 50, 50, 64)   256         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 50, 50, 64)   256         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 50, 50, 64)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 50, 50, 64)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 50, 50, 64)   0           activation_149[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 50, 50, 64)   36928       add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 50, 50, 64)   256         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 50, 50, 64)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 50, 50, 64)   36928       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 50, 50, 64)   256         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 50, 50, 64)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 50, 50, 64)   0           add_52[0][0]                     \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 25, 25, 128)  73856       add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 25, 25, 128)  512         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 25, 25, 128)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 25, 25, 128)  32896       add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 25, 25, 128)  147584      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 25, 25, 128)  512         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 25, 25, 128)  512         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 25, 25, 128)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 25, 25, 128)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 25, 25, 128)  0           activation_154[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 25, 25, 128)  147584      add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 25, 25, 128)  512         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 25, 25, 128)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 25, 25, 128)  147584      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 25, 25, 128)  512         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 25, 25, 128)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 25, 25, 128)  0           add_54[0][0]                     \n",
      "                                                                 activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 13, 13, 256)  295168      add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 13, 13, 256)  1024        conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 13, 13, 256)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 13, 13, 256)  131328      add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 13, 13, 256)  590080      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 13, 13, 256)  1024        conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 13, 13, 256)  1024        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 13, 13, 256)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 13, 13, 256)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 13, 13, 256)  0           activation_159[0][0]             \n",
      "                                                                 activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 13, 13, 256)  590080      add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 13, 13, 256)  1024        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 13, 13, 256)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 13, 13, 256)  590080      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 13, 13, 256)  1024        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 13, 13, 256)  0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 13, 13, 256)  0           add_56[0][0]                     \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 7, 7, 512)    1180160     add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 7, 7, 512)    2048        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 7, 7, 512)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 7, 7, 512)    524800      add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 7, 7, 512)    2359808     activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 7, 7, 512)    2048        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 7, 7, 512)    2048        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 512)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 512)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 7, 7, 512)    0           activation_164[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 7, 7, 512)    2359808     add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 7, 7, 512)    2048        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 512)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 7, 7, 512)    2359808     activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 7, 7, 512)    2048        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 512)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 7, 7, 512)    0           add_58[0][0]                     \n",
      "                                                                 activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 7, 7, 157)    80541       add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 157)          0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 157)          0           global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,796,669\n",
      "Trainable params: 11,786,749\n",
      "Non-trainable params: 9,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 177s 5ms/step - loss: 3.2593 - acc: 0.2223 - val_loss: 3.0245 - val_acc: 0.2098\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 2.3983 - acc: 0.4016 - val_loss: 2.0961 - val_acc: 0.4802\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 1.5122 - acc: 0.6212 - val_loss: 2.0713 - val_acc: 0.5150\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 1.1379 - acc: 0.7078 - val_loss: 1.2668 - val_acc: 0.6793\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 0.9436 - acc: 0.7519 - val_loss: 1.1402 - val_acc: 0.7070\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 0.8147 - acc: 0.7807 - val_loss: 1.1726 - val_acc: 0.6935\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 0.7009 - acc: 0.8047 - val_loss: 1.0783 - val_acc: 0.7390\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 0.6000 - acc: 0.8320 - val_loss: 1.0499 - val_acc: 0.7460\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 0.5029 - acc: 0.8516 - val_loss: 1.0583 - val_acc: 0.7582\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 0.4094 - acc: 0.8753 - val_loss: 1.0992 - val_acc: 0.7510\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 170s 5ms/step - loss: 0.3308 - acc: 0.8981 - val_loss: 1.1545 - val_acc: 0.7562\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e8567cb0b338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnet_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m157\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-9b5e3e999cc4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# X_train reshape to [40000,100,100]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "model = Resnet_A(157)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
